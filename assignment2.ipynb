{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35afc6b0-0403-4feb-ab0e-d441211d6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import ast \n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import csv\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7c2f96-45a3-4b98-9b3c-507d81e87cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RAW_interactions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAW_interactions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mnext\u001b[39m(f)  \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RAW_interactions.csv'"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open(\"RAW_interactions.csv\", encoding=\"utf8\") as f:\n",
    "    next(f)  \n",
    "    for l in f:\n",
    "        fields = l.strip().split(\",\")  # Remove trailing newline and split by commas\n",
    "        dataset.append(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff5612f-1172-48c9-9d8c-7466ca9cfd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['38094',\n",
       " '40893',\n",
       " '2003-02-17',\n",
       " '4',\n",
       " 'Great with a salad. Cooked on top of stove for 15 minutes.Added a shake of cayenne and a pinch of salt.  Used low fat sour cream.  Thanks.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]\n",
    "#user_id, recipe_id, date, rating, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82505f2d-0271-4a7f-9553-2e8294b7f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ratings = {}\n",
    "\n",
    "for row in dataset:\n",
    "    # Validate that row has enough fields and fields are not empty\n",
    "    if len(row) >= 4 and row[1].strip() and row[3].strip():\n",
    "        recipe_id = row[1].strip()  # Clean whitespace\n",
    "        rating = row[3].strip()\n",
    "        \n",
    "        # Additional check: Ensure 'rating' is numeric, if applicable\n",
    "        if rating.isdigit():\n",
    "            # Add rating to the dictionary\n",
    "            if recipe_id not in recipe_ratings:\n",
    "                recipe_ratings[recipe_id] = []\n",
    "            recipe_ratings[recipe_id].append(int(rating))\n",
    "\n",
    "# Example output\n",
    "#for recipe_id, ratings in recipe_ratings.items():\n",
    "#    print(f\"Recipe ID: {recipe_id}, Ratings: {ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3940a9-4d56-454a-89c9-02a80e7416f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_features = []\n",
    "with open(\"RAW_recipes.csv\", encoding=\"utf8\") as f:\n",
    "    next(f)  \n",
    "    for l in f:\n",
    "        fields = l.strip().split(\",\")  # Remove trailing newline and split by commas\n",
    "        dataset_features.append(fields)\n",
    "#name, id, minutes, contributor_id, date, tags, nutrition, number of steps, steps, description, ingredients, n_ingredinets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d24e3e-0db7-42d8-93bb-26a19a4dc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_nutrition = {}\n",
    "'''\n",
    "with open(\"RAW_recipes.csv\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip the header\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) >= 7:  # Ensure the row has enough fields\n",
    "            recipe_id = row[1].strip()  # Recipe ID (assumed second column)\n",
    "            nutrition_data = row[6].strip()  # Nutrition field (assumed seventh column)\n",
    "\n",
    "            try:\n",
    "                # Safely parse the nutrition field\n",
    "                nutrition_list = ast.literal_eval(nutrition_data)\n",
    "\n",
    "                # Ensure the parsed data is a list and has at least 7 elements\n",
    "                if isinstance(nutrition_list, list) and len(nutrition_list) >= 7:\n",
    "                    total_fat = nutrition_list[1]  # Total fat (PDV)\n",
    "                    sugar = nutrition_list[2]      # Sugar (PDV)\n",
    "                    saturated_fat = nutrition_list[5]  # Saturated fat (PDV)\n",
    "\n",
    "                    # Validate that the values are non-negative numbers\n",
    "                    if all(isinstance(x, (int, float)) and x >= 0 for x in [total_fat, sugar, saturated_fat]):\n",
    "                        recipe_nutrition[recipe_id] = {\n",
    "                            \"total_fat\": total_fat,\n",
    "                            \"sugar\": sugar,\n",
    "                            \"saturated_fat\": saturated_fat\n",
    "                        }\n",
    "            except (ValueError, SyntaxError, TypeError):\n",
    "                # Skip rows with invalid nutrition data\n",
    "                continue\n",
    "'''\n",
    "with open(\"RAW_recipes.csv\", encoding=\"utf8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip the header\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) >= 12:  # Ensure the row has enough fields\n",
    "            recipe_id = row[1].strip()  # Recipe ID (assumed second column)\n",
    "            n_ingredients = row[11].strip()  # Number of ingredients field (assumed 12th column)\n",
    "\n",
    "            # Validate and store the number of ingredients\n",
    "            if n_ingredients.isdigit():  # Check if it's a valid number\n",
    "                recipe_nutrition[recipe_id] = {\n",
    "                    \"n_ingredients\": int(n_ingredients)\n",
    "                }\n",
    "# Example output\n",
    "#for recipe_id, nutrition in recipe_nutrition.items():\n",
    "#   print(f\"Recipe ID: {recipe_id}, Nutrition: {nutrition}\")\n",
    "#extract total_fat, sugar, and saturated_fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831687cb-8f54-4c0f-9a9d-aa4be200c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 115818\n",
      "Test set size: 115819\n"
     ]
    }
   ],
   "source": [
    "all_ids = list(recipe_nutrition.keys())\n",
    "random.shuffle(all_ids)\n",
    "\n",
    "# Calculate the split index (50/50)\n",
    "split_index = len(all_ids) // 2\n",
    "\n",
    "# Split keys into training and testing sets\n",
    "train_ids = all_ids[:split_index]\n",
    "test_ids = all_ids[split_index:]\n",
    "\n",
    "# Create train and test dictionaries\n",
    "train_set = {recipe_id: recipe_nutrition[recipe_id] for recipe_id in train_ids}\n",
    "test_set = {recipe_id: recipe_nutrition[recipe_id] for recipe_id in test_ids}\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8293616d-b061-4523-8afd-d68b00c8501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [ 4.37044222e+00 -2.93794302e-03]\n"
     ]
    }
   ],
   "source": [
    "def feature(datum):\n",
    "    feat = [1]  # Bias term\n",
    "    #feat.append(datum['total_fat'])      \n",
    "    #feat.append(datum['sugar'])          \n",
    "    #feat.append(datum['saturated_fat'])   \n",
    "    feat.append(datum['n_ingredients'])   \n",
    "    return feat\n",
    "\n",
    "X_train = numpy.asarray([feature(train_set[recipe_id]) for recipe_id in train_set])\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "Y_train = numpy.asarray([\n",
    "    numpy.mean(recipe_ratings[recipe_id]) if isinstance(recipe_ratings[recipe_id], list) else float(recipe_ratings[recipe_id])\n",
    "    for recipe_id in train_set\n",
    "])\n",
    "\n",
    "model = linear_model.LinearRegression(fit_intercept=False)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Model coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2512b314-b3e1-4d72-b611-519fbbcbd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9798872545545332\n",
      "Percent Correct: 14.47%\n"
     ]
    }
   ],
   "source": [
    "X_test = numpy.asarray([feature(test_set[recipe_id]) for recipe_id in test_set])\n",
    "test_recipe_ids = list(test_set.keys())\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "Y_test = numpy.asarray([\n",
    "    numpy.mean(recipe_ratings[recipe_id]) if isinstance(recipe_ratings[recipe_id], list) else float(recipe_ratings[recipe_id])\n",
    "    for recipe_id in test_recipe_ids\n",
    "])\n",
    "\n",
    "# Predict using the model\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "def balanced_error_rate(y_true, y_pred):\n",
    "    epsilon = 1e-10\n",
    "    relative_errors = numpy.abs((y_true - y_pred) / y_true+epsilon)\n",
    "    return numpy.mean(relative_errors)\n",
    "\n",
    "tolerance = 0.25\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = numpy.sum(numpy.abs(Y_pred - Y_test) <= tolerance)\n",
    "\n",
    "# Calculate percent correct\n",
    "percent_correct = (correct_predictions / len(Y_test)) * 100\n",
    "print(f\"Percent Correct: {percent_correct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e10a83-59b4-43ac-aa35-75b8e66cb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 698901, Validation: 7023, Test: 12455\n"
     ]
    }
   ],
   "source": [
    "#implementation of similarity/pop\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "#THIS HOLDS EVERYTHING\n",
    "# Load data function\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            user_id, recipe_id, rating = row[0], row[1], float(row[3])\n",
    "            data.append((user_id, recipe_id, rating))\n",
    "    return data\n",
    "\n",
    "# Load train, validation, and test data\n",
    "ratingsTrain = load_data(\"interactions_train.csv\")\n",
    "ratingsValid = load_data(\"interactions_validation.csv\")\n",
    "ratingsTest = load_data(\"interactions_test.csv\")\n",
    "\n",
    "print(f\"Training: {len(ratingsTrain)}, Validation: {len(ratingsValid)}, Test: {len(ratingsTest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73eeffa4-1c32-47e5-9246-5113d6576510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('27208', 1091), ('89204', 1075), ('32204', 897), ('39087', 894), ('69173', 787), ('54257', 758), ('22782', 738), ('68955', 681), ('25885', 677), ('28148', 666)]\n",
      "Number of popular recipes: 14382\n"
     ]
    }
   ],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerRecipe = defaultdict(list)\n",
    " \n",
    "for u, b, r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b, r))\n",
    "    ratingsPerRecipe[b].append((u, r))\n",
    "\n",
    "\n",
    "#any interaction/any rating was added\n",
    "recipeCount = defaultdict(int)\n",
    "\n",
    "for _, recipe, _ in ratingsTrain:\n",
    "    recipeCount[recipe] += 1\n",
    "\n",
    "\n",
    "mostPopular = list(recipeCount.items())\n",
    "\n",
    "# mostPopular = sorted(recipeCount.items(), key=lambda x: -x[1])\n",
    "mostPopular.sort(key=lambda x: x[1])\n",
    "mostPopular.reverse()\n",
    "\n",
    "\n",
    "print(mostPopular[:10])\n",
    "returnSet = set()\n",
    "count = 0\n",
    "totalInteractions = len(ratingsTrain)\n",
    "\n",
    "for recipeID, interactionCount in mostPopular:\n",
    "    count += interactionCount\n",
    "    returnSet.add(recipeID)\n",
    "    if count > totalInteractions / 2:  # Threshold for popularity\n",
    "        break\n",
    "\n",
    "print(f\"Number of popular recipes: {len(returnSet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accb6acf-7bb8-4f4b-a94f-b81014c7e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model accuracy for well-rated prediction: 0.15990317528121886\n"
     ]
    }
   ],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    intersection = len(s1 & s2)\n",
    "    union = len(s1 | s2)\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "rating_threshold = 4\n",
    "correct=0\n",
    "threshold_jaccard=0.01\n",
    "\n",
    "for user, recipe, actual_rating in ratingsValid:  # Iterate through the validation set\n",
    "    # Popularity prediction\n",
    "    popular_pred = recipe in returnSet\n",
    "\n",
    "    # Jaccard prediction\n",
    "    max_sim = 0\n",
    "    for read_recipe,_ in ratingsPerUser[user]:\n",
    "        users_for_recipe = set([u for u, _ in ratingsPerRecipe[recipe]])\n",
    "        users_for_read_recipe = set([u for u, _ in ratingsPerRecipe[read_recipe]])\n",
    "        sim = Jaccard(users_for_recipe, users_for_read_recipe)\n",
    "        if sim>0: print(sim)\n",
    "        max_sim = max(max_sim, sim)\n",
    "    jaccard_pred = max_sim > threshold_jaccard\n",
    "\n",
    "    # Hybrid prediction: A recipe is well-rated if it meets either popularity or Jaccard criteria\n",
    "    hybrid_pred = popular_pred and jaccard_pred\n",
    "\n",
    "    # Convert actual rating to a binary label: well-rated (1) or not well-rated (0)\n",
    "    actual = 1 if actual_rating >= rating_threshold else 0\n",
    "\n",
    "    # Check if the hybrid prediction matches the actual label\n",
    "    if hybrid_pred == actual:\n",
    "        correct += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(ratingsValid)\n",
    "print(f\"Hybrid model accuracy for well-rated prediction: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aee4db-c9b8-451d-bf10-4209227477ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a839e-ea31-456d-8cf7-9d2a38155fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
